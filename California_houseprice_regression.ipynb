{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ab1b75c-fd43-481c-8b77-cce2cc96bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2feeca54-0f11-41c9-bb37-0ceed707b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1:Load the California Housing dataset\n",
    "# -------------------------------------------------------------------------------\n",
    "california = fetch_california_housing(as_frame=True)\n",
    "#Convert the dataset into a pandas DataFrame \n",
    "df = california.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67d35019-4f0c-469e-9927-798112ebf788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  MedHouseVal  \n",
      "0    -122.23        4.526  \n",
      "1    -122.22        3.585  \n",
      "2    -122.24        3.521  \n",
      "3    -122.25        3.413  \n",
      "4    -122.25        3.422  \n"
     ]
    }
   ],
   "source": [
    "#Data Inspection:\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68aba2e6-d10d-4217-9e05-c5c33b91aa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
      "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
      "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
      "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
      "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
      "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
      "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
      "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
      "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
      "\n",
      "           AveOccup      Latitude     Longitude   MedHouseVal  \n",
      "count  20640.000000  20640.000000  20640.000000  20640.000000  \n",
      "mean       3.070655     35.631861   -119.569704      2.068558  \n",
      "std       10.386050      2.135952      2.003532      1.153956  \n",
      "min        0.692308     32.540000   -124.350000      0.149990  \n",
      "25%        2.429741     33.930000   -121.800000      1.196000  \n",
      "50%        2.818116     34.260000   -118.490000      1.797000  \n",
      "75%        3.282261     37.710000   -118.010000      2.647250  \n",
      "max     1243.333333     41.950000   -114.310000      5.000010  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dc2016c-62df-47b8-adc2-ea87a0d78519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MedInc       20640 non-null  float64\n",
      " 1   HouseAge     20640 non-null  float64\n",
      " 2   AveRooms     20640 non-null  float64\n",
      " 3   AveBedrms    20640 non-null  float64\n",
      " 4   Population   20640 non-null  float64\n",
      " 5   AveOccup     20640 non-null  float64\n",
      " 6   Latitude     20640 non-null  float64\n",
      " 7   Longitude    20640 non-null  float64\n",
      " 8   MedHouseVal  20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3274a-e954-436f-b1db-01263913d416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)Preprocessing\n",
    "# --------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7db28a5b-b102-47e1-98ac-2a666bd906bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedInc         0\n",
      "HouseAge       0\n",
      "AveRooms       0\n",
      "AveBedrms      0\n",
      "Population     0\n",
      "AveOccup       0\n",
      "Latitude       0\n",
      "Longitude      0\n",
      "MedHouseVal    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb61ee-107b-40d3-bee1-2beb52ab24f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is no null values in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0d29bca-6e3b-420b-930c-5bedca78c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y)\n",
    "x=df.drop('MedHouseVal',axis=1)\n",
    "y=df['MedHouseVal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c1c8286-0856-47d1-bdb2-32379ff35871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and testing sets\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da92d090-6411-4038-800e-b56f0760c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization\n",
    "scaler=StandardScaler()\n",
    "x_train_scaler=scaler.fit_transform(x_train)\n",
    "x_test_scaler=scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "573e06c3-eb1a-458f-a7df-28194a4a9abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing:\n",
      "The absence of missing values simplified the preprocessing.Feature scaling (standardization) was crucial due to the wide variations in the ranges of the features.We used StandardScaler to transform the features so that they have a mean of 0 and a standard deviation of 1. This ensures that all features contribute equally to the model.\n"
     ]
    }
   ],
   "source": [
    "# Explanation\n",
    "print(\"preprocessing:\")\n",
    "print(\"The absence of missing values simplified the preprocessing.Feature scaling (standardization) was crucial due to the wide variations in the ranges of the features.We used StandardScaler to transform the features so that they have a mean of 0 and a standard deviation of 1. This ensures that all features contribute equally to the model.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2206f647-2f4e-4d45-8e7c-058c86cedd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3)Regression Algorithm Implementation\n",
    "# ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d42ce6b3-7c11-4031-bf9a-aabefa5cb537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "Explanation: Linear Regression models the relationship between the features and the target variable as a linear equation. It's suitable when the relationship is approximately linear.\n"
     ]
    }
   ],
   "source": [
    "# 1)Linear regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "y_pred_lr = lr.predict(x_test)\n",
    "\n",
    "print(\"Linear Regression:\")\n",
    "print(\"Explanation: Linear Regression models the relationship between the features and the target variable as a linear equation. It's suitable when the relationship is approximately linear.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c040885b-de42-40ca-aff4-26ab6da88044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Regressor:\n",
      "Explanation: Decision Tree Regressor partitions the feature space into rectangular regions and fits a simple constant model within each region. It can capture non-linear relationships but is prone to overfitting.\n"
     ]
    }
   ],
   "source": [
    "# 2)Decision Tree Regressor\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "dt.fit(x_train, y_train)\n",
    "y_pred_dt = dt.predict(x_test)\n",
    "\n",
    "print(\"\\nDecision Tree Regressor:\")\n",
    "print(\"Explanation: Decision Tree Regressor partitions the feature space into rectangular regions and fits a simple constant model within each region. It can capture non-linear relationships but is prone to overfitting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdb5e14a-28a6-45b6-a437-1c6190c7a89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Regressor:\n",
      "Explanation: Random Forest Regressor is an ensemble method that builds multiple decision trees and averages their predictions. It reduces overfitting and improves generalization.\n"
     ]
    }
   ],
   "source": [
    "# 3)Random Forest Regressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "\n",
    "print(\"\\nRandom Forest Regressor:\")\n",
    "print(\"Explanation: Random Forest Regressor is an ensemble method that builds multiple decision trees and averages their predictions. It reduces overfitting and improves generalization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9a1c0a3-274e-4d0f-89c4-e0c4f19771dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Regressor:\n",
      "Explanation: Gradient Boosting Regressor is another ensemble method that builds trees sequentially, with each tree correcting the errors of the previous ones. It often achieves high accuracy.\n"
     ]
    }
   ],
   "source": [
    "# 4)Gradient Boosting Regressor\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "gb.fit(x_train, y_train)\n",
    "y_pred_gb = gb.predict(x_test)\n",
    "\n",
    "print(\"\\nGradient Boosting Regressor:\")\n",
    "print(\"Explanation: Gradient Boosting Regressor is another ensemble method that builds trees sequentially, with each tree correcting the errors of the previous ones. It often achieves high accuracy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8cac902-4b76-427e-b18f-162277a121e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Regressor (SVR):\n",
      "Explanation: SVR maps the features into a high-dimensional space and finds the best-fitting hyperplane. It's effective in high-dimensional spaces and can handle non-linear relationships using kernel functions.\n"
     ]
    }
   ],
   "source": [
    "# 5)Support Vector Regressor (SVR)\n",
    "svr = SVR()\n",
    "svr.fit(x_train, y_train)\n",
    "y_pred_svr = svr.predict(x_test)\n",
    "\n",
    "print(\"\\nSupport Vector Regressor (SVR):\")\n",
    "print(\"Explanation: SVR maps the features into a high-dimensional space and finds the best-fitting hyperplane. It's effective in high-dimensional spaces and can handle non-linear relationships using kernel functions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15fc971-3f75-4473-940f-6294bc97e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Model Evaluation and Comparison \n",
    "# -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aef04388-d3c1-44ea-83ae-309da1c269e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for each model individually\n",
    "# linear regression:\n",
    "mse_lr= mean_squared_error(y_test, y_pred_lr)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# Dicision tree regressor\n",
    "mse_dt=mean_squared_error(y_test,y_pred_dt)\n",
    "mae_dt=mean_absolute_error(y_test,y_pred_dt)\n",
    "r2_dt=mean_squared_error(y_test,y_pred_dt)\n",
    "\n",
    "# Random forest regressor\n",
    "mse_rf=mean_squared_error(y_test,y_pred_rf)\n",
    "mae_rf=mean_absolute_error(y_test,y_pred_rf)\n",
    "r2_rf=mean_squared_error(y_test,y_pred_rf)\n",
    "\n",
    "# Gradient Boosting regressor\n",
    "mse_gb=mean_squared_error(y_test,y_pred_gb)\n",
    "mae_gb=mean_absolute_error(y_test,y_pred_gb)\n",
    "r2_gb=mean_squared_error(y_test,y_pred_gb)\n",
    "\n",
    "# SVR\n",
    "mse_svr=mean_squared_error(y_test,y_pred_svr)\n",
    "mae_svr=mean_absolute_error(y_test,y_pred_svr)\n",
    "r2_svr=mean_squared_error(y_test,y_pred_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c922eb73-9031-4be2-b42f-9ab7fd68f1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation:\n",
      "                        MSE       MAE        R2\n",
      "Linear Regression  0.555892  0.533200  0.575788\n",
      "Decision Tree      0.495235  0.454679  0.495235\n",
      "Random Forest      0.255368  0.327543  0.255368\n",
      "Gradient Boosting  0.293997  0.371643  0.293997\n",
      "SVR                1.332012  0.859951  1.332012\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame to display the results\n",
    "results = {\n",
    "    \"Linear Regression\": [mse_lr, mae_lr, r2_lr],\n",
    "    \"Decision Tree\": [mse_dt, mae_dt, r2_dt],\n",
    "    \"Random Forest\": [mse_rf, mae_rf, r2_rf],\n",
    "    \"Gradient Boosting\": [mse_gb, mae_gb, r2_gb],\n",
    "    \"SVR\": [mse_svr, mae_svr, r2_svr]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results, index=[\"MSE\", \"MAE\", \"R2\"]).T\n",
    "\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a1f0b5a-883f-4865-9490-4e72bbce7f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Performing Model: Random Forest (Lowest MSE)\n",
      "Worst Performing Model: SVR (Highest MSE)\n"
     ]
    }
   ],
   "source": [
    "# The best-performing algorithm and worst-performing algorithm\n",
    "best_model = results_df['MSE'].idxmin()\n",
    "worst_model = results_df['MSE'].idxmax()\n",
    "\n",
    "print(f\"\\nBest Performing Model: {best_model} (Lowest MSE)\")\n",
    "print(f\"Worst Performing Model: {worst_model} (Highest MSE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d84e218f-19d9-44fa-9b5f-05c2b155801c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Performing Model: Random Forest=It has the lowest MSE (0.255368) and the lowest MAE (0.327543) compared to all other models.While the R2 score is not the highest, the MSE and MAE are the most important factors for this evaluation.'Random Forest, being an ensemble method, effectively reduces overfitting and captures complex relationships in the data. Its ability to average predictions from multiple decision trees leads to more robust and accurate results.\n",
      "Worst Performing Model: SVR =It has the highest MSE (1.332012) and the highest MAE (0.859951).It also has the highest R2, which indicates a problem with the model. the R2 should be between 0 and 1. An R2 greater than one indicates that the model is fitting the noise within the data.''SVR's performance is highly dependent on the choice of kernel and hyperparameters. In this case, the default parameters or the chosen kernel might not be suitable for the California Housing dataset. Also, the high MSE indicates that the model's predictions are significantly deviating from the actual values. The extremely high R2 shows the model is not working correctly.'\n"
     ]
    }
   ],
   "source": [
    "# Explanation of Model Evaluation:\n",
    "print(\"Best Performing Model: Random Forest=It has the lowest MSE (0.255368) and the lowest MAE (0.327543) compared to all other models.While the R2 score is not the highest, the MSE and MAE are the most important factors for this evaluation.'Random Forest, being an ensemble method, effectively reduces overfitting and captures complex relationships in the data. Its ability to average predictions from multiple decision trees leads to more robust and accurate results.\")\n",
    "\n",
    "print(\"Worst Performing Model: SVR =It has the highest MSE (1.332012) and the highest MAE (0.859951).It also has the highest R2, which indicates a problem with the model. the R2 should be between 0 and 1. An R2 greater than one indicates that the model is fitting the noise within the data.''SVR's performance is highly dependent on the choice of kernel and hyperparameters. In this case, the default parameters or the chosen kernel might not be suitable for the California Housing dataset. Also, the high MSE indicates that the model's predictions are significantly deviating from the actual values. The extremely high R2 shows the model is not working correctly.'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb86cf5-0cf0-4d2d-955e-91d207906c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
